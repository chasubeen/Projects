# **ResNet50 ëª¨ë¸ë§ ê²°ê³¼**

## **1ï¸âƒ£Baseline**  
### **- ResNet?**  
- ì¼ë°˜ì ìœ¼ë¡œëŠ” ì‹ ê²½ë§ì˜ ê¹Šì´ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ ë”¥ëŸ¬ë‹ ì„±ëŠ¥ì´ ì¢‹ì•„ì§
  - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) ë…¼ë¬¸ì— ì˜í•˜ë©´ ì‹ ê²½ë§ì€ ê¹Šì´ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ë‹¤ê°€ ì¼ì •í•œ ë‹¨ê³„ì— ë‹¤ë‹¤ë¥´ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë‚˜ë¹ ì§„ë‹¤ê³  í•¨
- ê¹Šì–´ì§„ ì‹ ê²½ë§ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ **ë ˆì§€ë“€ì–¼(residual, ì”ì°¨)** ê°œë… ë„ì…
- Residual blockì„ ì´ìš©í•´ ê¸°ìš¸ê¸°ê°€ ì˜ ì „íŒŒë  ìˆ˜ ìˆë„ë¡ ì¼ì¢…ì˜ **ìˆì»·**ì„ ë§Œë“¤ì–´ ì¤Œ -> ê¸°ìš¸ê¸° ì†Œë©¸ ë¬¸ì œ ë°©ì§€
- VGG19 êµ¬ì¡°ë¥¼ ë¼ˆëŒ€ë¡œ í•˜ë©°, ê±°ê¸°ì— í•©ì„±ê³± ì¸µë“¤ì„ ì¶”ê°€í•´ì„œ ê¹Šê²Œ ë§Œë“  í›„ ìˆì»·ë“¤ì„ ì¶”ê°€í•œ ëª¨ë¸  
  
<img src = "https://user-images.githubusercontent.com/98953721/220263791-69b1bdfc-56e3-4293-81d3-61ad2a21ac9c.png" width = 250 height = 250> <img src = "https://user-images.githubusercontent.com/98953721/220263979-2c5d7298-96ba-437c-acaa-b6b108328bb6.png" width = 250 height = 250>  
<img src = "https://user-images.githubusercontent.com/98953721/220264178-12a39f1b-93a5-495d-8e94-f29faa654545.png" width = 350 height = 350> 

### **- êµ¬ì¡°**

<img src = "https://user-images.githubusercontent.com/98953721/220259257-0074e59d-1b4b-4d9c-8af8-2beb3a10b782.png" width = 700 height = 200>

<img src = "https://user-images.githubusercontent.com/98953721/220260021-579b1f5f-a28e-4379-a9ce-20c1a4f85dce.png" width = 700 height = 100>
<img src = "https://user-images.githubusercontent.com/98953721/220261298-fa159988-f9e1-4d61-9567-13ba1e6f3fe9.png" width = 700 height = 700>
<img src = "https://user-images.githubusercontent.com/98953721/220261377-3c9d2861-df47-4b3e-9a68-ec913cf1e417.png" width = 700 height = 700>
<img src = "https://user-images.githubusercontent.com/98953721/220261615-2cecac1e-9fd9-4559-b999-5fee6c74c9e5.png" width = 700 height = 950>
<img src = "https://user-images.githubusercontent.com/98953721/220261989-c674f291-579b-4d07-b7b7-8d52dd0d0356.png" width = 700 height = 950>
<img src = "https://user-images.githubusercontent.com/98953721/220262064-537e55fe-ff1b-4bb2-83e1-fc1c5aa4abda.png" width = 700 height = 70>

### **- ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ head ë¶€ë¶„ ìˆ˜ì •**
  - 7ê°œ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸
<img src = "https://user-images.githubusercontent.com/98953721/220263554-daef77e6-ecf2-46a4-9b55-7cddb47da69c.png" width = 700 height = 70>

## **2ï¸âƒ£ ì„±ëŠ¥ ìµœì í™” ê²°ê³¼**
### **âœ… Case 1**
- Optimizer: SGD(Stochastic Gradient Descent/ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•)
- batch size: 64
- Epoch: 100
- ì†ì‹¤í•¨ìˆ˜: CrossEntropyLoss

- ëª©í‘œ: ì ì ˆí•œ **learning rate** ì°¾ê¸°
  - lr_scheduler, early stopping ì ìš©

|   |**sgd_ver1**|**sgd_ver2**|**sgd_ver3**|
|------|-------|-------|-------|
|**ì´ˆê¸° learning rate**|1e-2|1e-3|1e-4|
|**min_lr**|1e-10|1e-12|1e-12|
|**Best Acc**|**0.6639**|0.6420|0.5601|

### **âœ… Case 2**
- ëª©í‘œ: ì ì ˆí•œ **batch size** ì°¾ê¸°
- batch sizeê°€ **í´** ë•Œ
  - í•œ ë²ˆ í•™ìŠµí•  ë•Œ ë§ì€ ë°ì´í„°ë¡œ í•™ìŠµ
  - ë¹ ë¥¸ í•™ìŠµ/ìˆ˜ë ´ ì†ë„ -> local optimaì— ë¹ ì§ˆ í™•ë¥ ì´ ì‘ìŒ
  - ì‘ì€ ë°°ì¹˜ì— ë¹„í•´ ê³¼ì í•© ìœ„í—˜ì„± ì¦ê°€(batchê°€ í¬ë©´ ê³„ì‚°ë˜ëŠ” lossê°’ì˜ í¸ì°¨ê°€ ì‘ìœ¼ë¯€ë¡œ)
- batch sizeê°€ **ì‘ì„** ë•Œ
  - 1 epoch ë‹¹ iterationì´ í¬ê¸° ë•Œë¬¸ì— stepì´ ë§ì•„ì§
  - ì‘ì€ ë°ì´í„°ë¡œ í•™ìŠµ -> lossì˜ ë¶„ì‚°ì´ ì»¤ì„œ ì •ê·œí™” íš¨ê³¼ê°€ ìˆìŒ, ì¡°ê¸ˆ ë” ë‹¤ì–‘í•˜ê³  ì˜ˆë¦¬í•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆìŒ
  - ê¸´ í•™ìŠµì‹œê°„, ë§ì€ step ìˆ˜ë¡œ ì¸í•´ local minimaì— ë¹ ì§ˆ ìœ„í—˜ì„± ì¦ê°€

- ì¼ë°˜ì ìœ¼ë¡œ learning rateì™€ batch sizeëŠ” **ì–‘ì˜ ìƒê´€ê´€ê³„**ë¥¼ ë³´ì„ -> ë™ì‹œ ì¡°ì •ì´ ìš”êµ¬ë¨
  - ê°ê°ì˜ ê²½ìš°ì— ëŒ€í•´ batch sizeì™€ learning rateë§Œì„ ì¡°ì •/ ë‚˜ë¨¸ì§€ ì¡°ê±´ì€ **Case 1**ê³¼ ë™ì¼

|   |**sgd_ver4**|**sgd_ver5**|**sgd_ver6**|**sgd_ver7**|
|------|-------|-------|-------|-------|
|**batch**|128|128|256|256|
|**ì´ˆê¸° lr**|1e-2|1e-3|1e-1|1e-2|
|**min_lr**|1e-10|1e-12|1e-10|1e-12|
|**Best Acc**|**0.6642**|0.6104|0.6183|0.6628|

- - -

### **âœ… Case 3**
- Optimizer ë³€ê²½(SGD -> **Adam**)
- batch size: 64
- Epoch: 100
- ì†ì‹¤í•¨ìˆ˜: CrossEntropyLoss

- ëª©í‘œ: ì ì ˆí•œ **learning rate** ì°¾ê¸°

|   |**adam_ver1**|**adam_ver2**|**adam_ver3**|
|------|-------|-------|-------|
|**ì´ˆê¸° learning rate**|1e-3|1e-4|1e-5|
|**min_lr**|1e-13|1e-14|1e-15|
|**Best Acc**|0.6442|**0.6626**|0.5712|

### **âœ… Case 4**
- ëª©í‘œ: ì ì ˆí•œ **batch size** ì°¾ê¸°
  - ê°ê°ì˜ ê²½ìš°ì— ëŒ€í•´ batch sizeì™€ learning rateë§Œì„ ì¡°ì •
  - ë‚˜ë¨¸ì§€ ì¡°ê±´ì€ **Case 3**ê³¼ ë™ì¼ 

|   |**adam_ver4**|**adam_ver5**|**adam_ver6**|**adam_ver7**|
|------|-------|-------|-------|-------|
|**batch**|128|128|256|256|
|**ì´ˆê¸° lr**|1e-3|1e-4|1e-2|1e-3|
|**min_lr**|1e-13|1e-14|1e-12|1e-13|
|**Best Acc**|0.6521|0.6531|0.5909|**0.6654**|

### **âœ… Case 5**
- ëª©í‘œ: **L2 ì •ê·œí™”(L2 ê·œì œ)** ì ìš©
  - ê·œì œ(Regularization): í•™ìŠµì´ ê³¼ëŒ€ì í•©ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ ì ì¼ì¢…ì˜ penaltyë¥¼ ë¶€ì—¬í•˜ëŠ” ê²ƒ
  - ê° ê°€ì¤‘ì¹˜ ì œê³±ì˜ í•©ì— ê·œì œ ê°•ë„ë¥¼ ê³±í•œ ê°’($Error = MSE + Î±ğ‘¤^2$)
  - ì›í˜•ì˜ ê²½ê³„ë¥¼ ë§Œë“¤ì–´ì„œ í•™ìŠµ ë°ì´í„°ì…‹ì˜ ìµœì  ì§€ì ì¸ w* ì— ë„ë‹¬í•˜ì§€ ëª»í•˜ê²Œ í•˜ê³  ê²½ê³„ ë‚´ë¶€ì˜ v* ê¹Œì§€ë§Œ ë„ë‹¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ì‹
  - Optimizerë¡œ Adamì„ ì‚¬ìš©í•  ê²½ìš° **weight_decay** íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŒ
    - ê°’ì´ í´ìˆ˜ë¡ ê·œì œ ê°•ë„ê°€ ê°•í•œ ê²ƒì„ ì˜ë¯¸ -> ê°€ì¤‘ì¹˜ê°€ ë” ë§ì´ ê°ì†Œë¨
  ```Python
  optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-3)
  ```
- batch size: 128, 256
- Epoch: 100
- ì†ì‹¤í•¨ìˆ˜: CrossEntropyLoss
- learning rate
  - ê°ê°ì˜ batch sizeì— ëŒ€í•´ ì„±ëŠ¥ì´ ê°€ì¥ **ì¢‹ì•˜ë˜** ëª¨ë¸ë“¤ì˜ learning rate í™œìš©
  - batch = 128: ì´ˆê¸°(1e-4), min_lr(1e-14)
  - batch = 256: ì´ˆê¸°(1e-3), min_lr(1e-13)

|   |**adam_ver8**|**adam_ver9**|**adam_ver10**|**adam_ver11**|
|------|-------|-------|-------|-------|
|**batch**|128|128|256|256|
|**ì´ˆê¸° lr**|1e-4|1e-4|1e-3|1e-3|
|**min_lr**|1e-14|1e-14|1e-13|1e-13|
|**L2 ê·œì œ ê°•ë„**|1e-4|1e-3|1e-4|1e-3|
|**Best Acc**|0.6571|**0.6658**|0.6653|0.6525|

## **âœ… Case 6**
- ëª©í‘œ: **êµë€ ë¼ë²¨ë§** ì ìš©
  - ë¶„ë¥˜(classification) ë¬¸ì œì—ì„œ ì¼ì • ë¹„ìœ¨ì˜ ë¼ë²¨ì„ ì˜ë„ì ìœ¼ë¡œ ì˜ëª»ëœ ë¼ë²¨ë¡œ ë§Œë“¤ì–´ì„œ í•™ìŠµì„ ë°©í•´í•˜ëŠ” ë°©ì‹
    - ë‹¨ìˆœí•œ ë°©ì‹ì´ì§€ë§Œ ê³¼ì í•©ì„ íš¨ê³¼ì ìœ¼ë¡œ ë§‰ì„ ìˆ˜ ìˆìŒ
  - ì†ì‹¤ì¸µ(loss layer)ì— ê·œì œë¥¼ ë‘ëŠ” ë°©ì‹
    - í•™ìŠµ ê³¼ì •ì—ì„œ êµë€ ë¼ë²¨ì„ ì¶”ê°€í•œ í›„ í•™ìŠµ ì§„í–‰
- ì´ì „ì˜ ëª¨ë¸ë“¤ ì¤‘ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ë˜ ëª¨ë¸ êµ¬ì¡°ë¡œ ëª¨ë¸ë§
  - Optimizer: Adam
  - batch size: 128
  - Epoch: 100
  - learning rate
    - ì´ˆê¸°: 1e-4
    - min_lr: 1e-14
  - ì†ì‹¤í•¨ìˆ˜: CrossEntropyLoss
  - weight_decay: 1e-3

|   |**adam_ver12**|**adam_ver13**|**adam_ver14**|
|------|-------|-------|-------|
|**alpha(êµë€ %)**|10|15|20|
|**Best Acc**|**0.6177**|0.5902|0.5610|

- ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŒ
---

## **#ï¸âƒ£ References**
- [ê¸°ìˆ ë¸”ë¡œê·¸_ê³¼ì í•© ë°©ì§€ë¥¼ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ](https://yeong-jin-data-blog.tistory.com/entry/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98-%EC%8A%A4%ED%84%B0%EB%94%94-%EA%B3%BC%EC%A0%81%ED%95%A9-%EB%B0%A9%EC%A7%80%EB%A5%BC-%ED%86%B5%ED%95%9C-%EB%AA%A8%EB%8D%B8-%EC%84%B1%EB%8A%A5-%EA%B0%9C%EC%84%A0-%EB%B0%A9%EB%B2%95)  
- [êµë€ ë¼ë²¨ë§ ê´€ë ¨ ë…¼ë¬¸](https://arxiv.org/abs/1605.00055)  
- [êµë€ ë¼ë²¨ë§ êµ¬í˜„](https://github.com/amirhfarzaneh/disturblabel-pytorch/blob/master/main.py)
