{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5809f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cc65a",
   "metadata": {},
   "source": [
    "# **0. ResNet 모델 개요**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768de04d",
   "metadata": {},
   "source": [
    "- 일반적으로는 신경망의 깊이가 깊어질수록 딥러닝 성능이 좋아짐\n",
    "  > \"Deep Residual Learning for Image Recognition\" 논문에 의하면 신경망은 깊이가 깊어질수록 성능이 좋아지다가 일정한 단계에 다다르면 오히려 성능이 나빠진다고 함\n",
    "  - 깊어진 신경망을 효과적으로 학습하기 위한 방법으로 **레지듀얼(residual, 잔차)** 개념 도입\n",
    "- Residual block을 이용해 기울기가 잘 전파될 수 있도록 일종의 숏컷을 만들어 줌\n",
    "  > 기울기 소멸 문제 방지\n",
    "- VGG19 구조를 뼈대로 하며, 거기에 합성곱 층들을 추가해서 깊게 만든 후 숏컷들을 추가하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b3872",
   "metadata": {},
   "source": [
    "### **용어 정리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952afad",
   "metadata": {},
   "source": [
    "#### **1. 블록(block)**  \n",
    "- 계층의 묶음\n",
    "- 여러 합성곱 층을 하나로 묶은 단위\n",
    "\n",
    "#### **2. 레지듀얼 블록(residual block)**\n",
    "- 기울기가 잘 전파될 수 있도록 일종의 숏컷(shortcut)을 만들어 주는 것\n",
    "- 기울기 소멸 방지\n",
    "- 여러 계층을 묶어 하나의 레지듀얼 블록 생성\n",
    "    - 레지듀얼 블록을 여러 개 쌓은 것이 ResNet\n",
    "    \n",
    "#### **3. 병목 블록(bottleneck block)**\n",
    "- 계층의 깊이가 깊어질 때 파라미터의 수가 무제한으로 커지는 것을 방지\n",
    "    - ResNet50의 경우 깊이가 깊어졌음에도 파라미터의 수가 감소\n",
    "- 3x3 합성곱층의 앞뒤로 1x1 합성곱층을 붙임\n",
    "    - 1x1 합성곱층의 채널 수를 조절하면서 차원 확대/축소\n",
    "\n",
    "#### **4. 아이덴티티 매핑(identity mapping, 숏컷(shortcut))**\n",
    "- 입력 x가 어떤 함수를 통과하더라도 다시 x라는 형태로 출력되도록 하는 것\n",
    "- 아이덴티티 블록: 입력 차원 == 출력 차원\n",
    "\n",
    "#### **5. 다운샘플(down-sample)**\n",
    "- 특성 맵 크기를 줄이기 위한 것\n",
    "    - 풀링과 같은 역할\n",
    "- 아이덴티티 매핑을 적용하기 위해 블록을 넘어갈 때 형태를 맞춰주는 역할\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f78aa",
   "metadata": {},
   "source": [
    "# **1. ResNet 모델 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433a49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\doroc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "c:\\users\\doroc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained = True) # 이미 학습된 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8a76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary # 모델 구조 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959b47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2          [1, 64, 112, 112]             128\n",
      "              ReLU-3          [1, 64, 112, 112]               0\n",
      "         MaxPool2d-4            [1, 64, 56, 56]               0\n",
      "            Conv2d-5            [1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6            [1, 64, 56, 56]             128\n",
      "              ReLU-7            [1, 64, 56, 56]               0\n",
      "            Conv2d-8            [1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9            [1, 64, 56, 56]             128\n",
      "             ReLU-10            [1, 64, 56, 56]               0\n",
      "           Conv2d-11           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12           [1, 256, 56, 56]             512\n",
      "           Conv2d-13           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14           [1, 256, 56, 56]             512\n",
      "             ReLU-15           [1, 256, 56, 56]               0\n",
      "       Bottleneck-16           [1, 256, 56, 56]               0\n",
      "           Conv2d-17            [1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18            [1, 64, 56, 56]             128\n",
      "             ReLU-19            [1, 64, 56, 56]               0\n",
      "           Conv2d-20            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21            [1, 64, 56, 56]             128\n",
      "             ReLU-22            [1, 64, 56, 56]               0\n",
      "           Conv2d-23           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24           [1, 256, 56, 56]             512\n",
      "             ReLU-25           [1, 256, 56, 56]               0\n",
      "       Bottleneck-26           [1, 256, 56, 56]               0\n",
      "           Conv2d-27            [1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28            [1, 64, 56, 56]             128\n",
      "             ReLU-29            [1, 64, 56, 56]               0\n",
      "           Conv2d-30            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31            [1, 64, 56, 56]             128\n",
      "             ReLU-32            [1, 64, 56, 56]               0\n",
      "           Conv2d-33           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34           [1, 256, 56, 56]             512\n",
      "             ReLU-35           [1, 256, 56, 56]               0\n",
      "       Bottleneck-36           [1, 256, 56, 56]               0\n",
      "           Conv2d-37           [1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38           [1, 128, 56, 56]             256\n",
      "             ReLU-39           [1, 128, 56, 56]               0\n",
      "           Conv2d-40           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41           [1, 128, 28, 28]             256\n",
      "             ReLU-42           [1, 128, 28, 28]               0\n",
      "           Conv2d-43           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44           [1, 512, 28, 28]           1,024\n",
      "           Conv2d-45           [1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46           [1, 512, 28, 28]           1,024\n",
      "             ReLU-47           [1, 512, 28, 28]               0\n",
      "       Bottleneck-48           [1, 512, 28, 28]               0\n",
      "           Conv2d-49           [1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50           [1, 128, 28, 28]             256\n",
      "             ReLU-51           [1, 128, 28, 28]               0\n",
      "           Conv2d-52           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53           [1, 128, 28, 28]             256\n",
      "             ReLU-54           [1, 128, 28, 28]               0\n",
      "           Conv2d-55           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56           [1, 512, 28, 28]           1,024\n",
      "             ReLU-57           [1, 512, 28, 28]               0\n",
      "       Bottleneck-58           [1, 512, 28, 28]               0\n",
      "           Conv2d-59           [1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60           [1, 128, 28, 28]             256\n",
      "             ReLU-61           [1, 128, 28, 28]               0\n",
      "           Conv2d-62           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63           [1, 128, 28, 28]             256\n",
      "             ReLU-64           [1, 128, 28, 28]               0\n",
      "           Conv2d-65           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66           [1, 512, 28, 28]           1,024\n",
      "             ReLU-67           [1, 512, 28, 28]               0\n",
      "       Bottleneck-68           [1, 512, 28, 28]               0\n",
      "           Conv2d-69           [1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70           [1, 128, 28, 28]             256\n",
      "             ReLU-71           [1, 128, 28, 28]               0\n",
      "           Conv2d-72           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73           [1, 128, 28, 28]             256\n",
      "             ReLU-74           [1, 128, 28, 28]               0\n",
      "           Conv2d-75           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76           [1, 512, 28, 28]           1,024\n",
      "             ReLU-77           [1, 512, 28, 28]               0\n",
      "       Bottleneck-78           [1, 512, 28, 28]               0\n",
      "           Conv2d-79           [1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80           [1, 256, 28, 28]             512\n",
      "             ReLU-81           [1, 256, 28, 28]               0\n",
      "           Conv2d-82           [1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83           [1, 256, 14, 14]             512\n",
      "             ReLU-84           [1, 256, 14, 14]               0\n",
      "           Conv2d-85          [1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86          [1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87          [1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88          [1, 1024, 14, 14]           2,048\n",
      "             ReLU-89          [1, 1024, 14, 14]               0\n",
      "       Bottleneck-90          [1, 1024, 14, 14]               0\n",
      "           Conv2d-91           [1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92           [1, 256, 14, 14]             512\n",
      "             ReLU-93           [1, 256, 14, 14]               0\n",
      "           Conv2d-94           [1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95           [1, 256, 14, 14]             512\n",
      "             ReLU-96           [1, 256, 14, 14]               0\n",
      "           Conv2d-97          [1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98          [1, 1024, 14, 14]           2,048\n",
      "             ReLU-99          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-100          [1, 1024, 14, 14]               0\n",
      "          Conv2d-101           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102           [1, 256, 14, 14]             512\n",
      "            ReLU-103           [1, 256, 14, 14]               0\n",
      "          Conv2d-104           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105           [1, 256, 14, 14]             512\n",
      "            ReLU-106           [1, 256, 14, 14]               0\n",
      "          Conv2d-107          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-109          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-110          [1, 1024, 14, 14]               0\n",
      "          Conv2d-111           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112           [1, 256, 14, 14]             512\n",
      "            ReLU-113           [1, 256, 14, 14]               0\n",
      "          Conv2d-114           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115           [1, 256, 14, 14]             512\n",
      "            ReLU-116           [1, 256, 14, 14]               0\n",
      "          Conv2d-117          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-119          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-120          [1, 1024, 14, 14]               0\n",
      "          Conv2d-121           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122           [1, 256, 14, 14]             512\n",
      "            ReLU-123           [1, 256, 14, 14]               0\n",
      "          Conv2d-124           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125           [1, 256, 14, 14]             512\n",
      "            ReLU-126           [1, 256, 14, 14]               0\n",
      "          Conv2d-127          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-129          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-130          [1, 1024, 14, 14]               0\n",
      "          Conv2d-131           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132           [1, 256, 14, 14]             512\n",
      "            ReLU-133           [1, 256, 14, 14]               0\n",
      "          Conv2d-134           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135           [1, 256, 14, 14]             512\n",
      "            ReLU-136           [1, 256, 14, 14]               0\n",
      "          Conv2d-137          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-139          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-140          [1, 1024, 14, 14]               0\n",
      "          Conv2d-141           [1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142           [1, 512, 14, 14]           1,024\n",
      "            ReLU-143           [1, 512, 14, 14]               0\n",
      "          Conv2d-144             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145             [1, 512, 7, 7]           1,024\n",
      "            ReLU-146             [1, 512, 7, 7]               0\n",
      "          Conv2d-147            [1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148            [1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149            [1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150            [1, 2048, 7, 7]           4,096\n",
      "            ReLU-151            [1, 2048, 7, 7]               0\n",
      "      Bottleneck-152            [1, 2048, 7, 7]               0\n",
      "          Conv2d-153             [1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154             [1, 512, 7, 7]           1,024\n",
      "            ReLU-155             [1, 512, 7, 7]               0\n",
      "          Conv2d-156             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157             [1, 512, 7, 7]           1,024\n",
      "            ReLU-158             [1, 512, 7, 7]               0\n",
      "          Conv2d-159            [1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160            [1, 2048, 7, 7]           4,096\n",
      "            ReLU-161            [1, 2048, 7, 7]               0\n",
      "      Bottleneck-162            [1, 2048, 7, 7]               0\n",
      "          Conv2d-163             [1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164             [1, 512, 7, 7]           1,024\n",
      "            ReLU-165             [1, 512, 7, 7]               0\n",
      "          Conv2d-166             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167             [1, 512, 7, 7]           1,024\n",
      "            ReLU-168             [1, 512, 7, 7]               0\n",
      "          Conv2d-169            [1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170            [1, 2048, 7, 7]           4,096\n",
      "            ReLU-171            [1, 2048, 7, 7]               0\n",
      "      Bottleneck-172            [1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173            [1, 2048, 1, 1]               0\n",
      "          Linear-174                  [1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size = (3,224,224),batch_size = 1,device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4ab3c",
   "metadata": {},
   "source": [
    "# **2. 데이터에 맞게 모델의 Head 부분 수정하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd81de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "model.fc = nn.Linear(2048,7) # 7개의 감정으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27169421",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 생성 함수\n",
    "def build_resnet50_based_model(device_name = 'cpu'):\n",
    "    device = torch.device(device_name)\n",
    "    model = models.resnet50(pretrained = True) # 이미 학습된 resnet50 모델 불러오기\n",
    "    # 일반 NN layer(FC layer)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "    model.fc = nn.Linear(2048,7) # 7개의 감정으로 분류\n",
    "    \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559a139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet50_based_model(device_name = 'cpu') # 모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6c2bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2          [1, 64, 112, 112]             128\n",
      "              ReLU-3          [1, 64, 112, 112]               0\n",
      "         MaxPool2d-4            [1, 64, 56, 56]               0\n",
      "            Conv2d-5            [1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6            [1, 64, 56, 56]             128\n",
      "              ReLU-7            [1, 64, 56, 56]               0\n",
      "            Conv2d-8            [1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9            [1, 64, 56, 56]             128\n",
      "             ReLU-10            [1, 64, 56, 56]               0\n",
      "           Conv2d-11           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12           [1, 256, 56, 56]             512\n",
      "           Conv2d-13           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14           [1, 256, 56, 56]             512\n",
      "             ReLU-15           [1, 256, 56, 56]               0\n",
      "       Bottleneck-16           [1, 256, 56, 56]               0\n",
      "           Conv2d-17            [1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18            [1, 64, 56, 56]             128\n",
      "             ReLU-19            [1, 64, 56, 56]               0\n",
      "           Conv2d-20            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21            [1, 64, 56, 56]             128\n",
      "             ReLU-22            [1, 64, 56, 56]               0\n",
      "           Conv2d-23           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24           [1, 256, 56, 56]             512\n",
      "             ReLU-25           [1, 256, 56, 56]               0\n",
      "       Bottleneck-26           [1, 256, 56, 56]               0\n",
      "           Conv2d-27            [1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28            [1, 64, 56, 56]             128\n",
      "             ReLU-29            [1, 64, 56, 56]               0\n",
      "           Conv2d-30            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31            [1, 64, 56, 56]             128\n",
      "             ReLU-32            [1, 64, 56, 56]               0\n",
      "           Conv2d-33           [1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34           [1, 256, 56, 56]             512\n",
      "             ReLU-35           [1, 256, 56, 56]               0\n",
      "       Bottleneck-36           [1, 256, 56, 56]               0\n",
      "           Conv2d-37           [1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38           [1, 128, 56, 56]             256\n",
      "             ReLU-39           [1, 128, 56, 56]               0\n",
      "           Conv2d-40           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41           [1, 128, 28, 28]             256\n",
      "             ReLU-42           [1, 128, 28, 28]               0\n",
      "           Conv2d-43           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44           [1, 512, 28, 28]           1,024\n",
      "           Conv2d-45           [1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46           [1, 512, 28, 28]           1,024\n",
      "             ReLU-47           [1, 512, 28, 28]               0\n",
      "       Bottleneck-48           [1, 512, 28, 28]               0\n",
      "           Conv2d-49           [1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50           [1, 128, 28, 28]             256\n",
      "             ReLU-51           [1, 128, 28, 28]               0\n",
      "           Conv2d-52           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53           [1, 128, 28, 28]             256\n",
      "             ReLU-54           [1, 128, 28, 28]               0\n",
      "           Conv2d-55           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56           [1, 512, 28, 28]           1,024\n",
      "             ReLU-57           [1, 512, 28, 28]               0\n",
      "       Bottleneck-58           [1, 512, 28, 28]               0\n",
      "           Conv2d-59           [1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60           [1, 128, 28, 28]             256\n",
      "             ReLU-61           [1, 128, 28, 28]               0\n",
      "           Conv2d-62           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63           [1, 128, 28, 28]             256\n",
      "             ReLU-64           [1, 128, 28, 28]               0\n",
      "           Conv2d-65           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66           [1, 512, 28, 28]           1,024\n",
      "             ReLU-67           [1, 512, 28, 28]               0\n",
      "       Bottleneck-68           [1, 512, 28, 28]               0\n",
      "           Conv2d-69           [1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70           [1, 128, 28, 28]             256\n",
      "             ReLU-71           [1, 128, 28, 28]               0\n",
      "           Conv2d-72           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73           [1, 128, 28, 28]             256\n",
      "             ReLU-74           [1, 128, 28, 28]               0\n",
      "           Conv2d-75           [1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76           [1, 512, 28, 28]           1,024\n",
      "             ReLU-77           [1, 512, 28, 28]               0\n",
      "       Bottleneck-78           [1, 512, 28, 28]               0\n",
      "           Conv2d-79           [1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80           [1, 256, 28, 28]             512\n",
      "             ReLU-81           [1, 256, 28, 28]               0\n",
      "           Conv2d-82           [1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83           [1, 256, 14, 14]             512\n",
      "             ReLU-84           [1, 256, 14, 14]               0\n",
      "           Conv2d-85          [1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86          [1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87          [1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88          [1, 1024, 14, 14]           2,048\n",
      "             ReLU-89          [1, 1024, 14, 14]               0\n",
      "       Bottleneck-90          [1, 1024, 14, 14]               0\n",
      "           Conv2d-91           [1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92           [1, 256, 14, 14]             512\n",
      "             ReLU-93           [1, 256, 14, 14]               0\n",
      "           Conv2d-94           [1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95           [1, 256, 14, 14]             512\n",
      "             ReLU-96           [1, 256, 14, 14]               0\n",
      "           Conv2d-97          [1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98          [1, 1024, 14, 14]           2,048\n",
      "             ReLU-99          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-100          [1, 1024, 14, 14]               0\n",
      "          Conv2d-101           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102           [1, 256, 14, 14]             512\n",
      "            ReLU-103           [1, 256, 14, 14]               0\n",
      "          Conv2d-104           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105           [1, 256, 14, 14]             512\n",
      "            ReLU-106           [1, 256, 14, 14]               0\n",
      "          Conv2d-107          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-109          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-110          [1, 1024, 14, 14]               0\n",
      "          Conv2d-111           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112           [1, 256, 14, 14]             512\n",
      "            ReLU-113           [1, 256, 14, 14]               0\n",
      "          Conv2d-114           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115           [1, 256, 14, 14]             512\n",
      "            ReLU-116           [1, 256, 14, 14]               0\n",
      "          Conv2d-117          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-119          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-120          [1, 1024, 14, 14]               0\n",
      "          Conv2d-121           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122           [1, 256, 14, 14]             512\n",
      "            ReLU-123           [1, 256, 14, 14]               0\n",
      "          Conv2d-124           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125           [1, 256, 14, 14]             512\n",
      "            ReLU-126           [1, 256, 14, 14]               0\n",
      "          Conv2d-127          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-129          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-130          [1, 1024, 14, 14]               0\n",
      "          Conv2d-131           [1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132           [1, 256, 14, 14]             512\n",
      "            ReLU-133           [1, 256, 14, 14]               0\n",
      "          Conv2d-134           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135           [1, 256, 14, 14]             512\n",
      "            ReLU-136           [1, 256, 14, 14]               0\n",
      "          Conv2d-137          [1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138          [1, 1024, 14, 14]           2,048\n",
      "            ReLU-139          [1, 1024, 14, 14]               0\n",
      "      Bottleneck-140          [1, 1024, 14, 14]               0\n",
      "          Conv2d-141           [1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142           [1, 512, 14, 14]           1,024\n",
      "            ReLU-143           [1, 512, 14, 14]               0\n",
      "          Conv2d-144             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145             [1, 512, 7, 7]           1,024\n",
      "            ReLU-146             [1, 512, 7, 7]               0\n",
      "          Conv2d-147            [1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148            [1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149            [1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150            [1, 2048, 7, 7]           4,096\n",
      "            ReLU-151            [1, 2048, 7, 7]               0\n",
      "      Bottleneck-152            [1, 2048, 7, 7]               0\n",
      "          Conv2d-153             [1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154             [1, 512, 7, 7]           1,024\n",
      "            ReLU-155             [1, 512, 7, 7]               0\n",
      "          Conv2d-156             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157             [1, 512, 7, 7]           1,024\n",
      "            ReLU-158             [1, 512, 7, 7]               0\n",
      "          Conv2d-159            [1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160            [1, 2048, 7, 7]           4,096\n",
      "            ReLU-161            [1, 2048, 7, 7]               0\n",
      "      Bottleneck-162            [1, 2048, 7, 7]               0\n",
      "          Conv2d-163             [1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164             [1, 512, 7, 7]           1,024\n",
      "            ReLU-165             [1, 512, 7, 7]               0\n",
      "          Conv2d-166             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167             [1, 512, 7, 7]           1,024\n",
      "            ReLU-168             [1, 512, 7, 7]               0\n",
      "          Conv2d-169            [1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170            [1, 2048, 7, 7]           4,096\n",
      "            ReLU-171            [1, 2048, 7, 7]               0\n",
      "      Bottleneck-172            [1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173            [1, 2048, 1, 1]               0\n",
      "          Linear-174                     [1, 7]          14,343\n",
      "================================================================\n",
      "Total params: 23,522,375\n",
      "Trainable params: 23,522,375\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.73\n",
      "Estimated Total Size (MB): 376.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(3,224,224),batch_size = 1,device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc29b5a",
   "metadata": {},
   "source": [
    "# **3. 손실함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55a60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286dc14",
   "metadata": {},
   "source": [
    "# **4. 옵티마이져 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a85581",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr = 1e-3,momentum = 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
